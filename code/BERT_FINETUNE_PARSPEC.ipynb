{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "9OI1fU7LhqyP"
      },
      "outputs": [],
      "source": [
        "## import the libs ##\n",
        "\n",
        "import torch, os\n",
        "import pandas as pd\n",
        "from transformers import pipeline, BertForSequenceClassification, BertTokenizerFast\n",
        "from torch.utils.data import Dataset\n",
        "from torch import cuda\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# !pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mP87A4t1iG1t",
        "outputId": "a4f1a9e6-7aeb-4147-bc00-a6b7a42056e6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## check device availability ##\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8_JImqzAiL7S"
      },
      "outputs": [],
      "source": [
        "## load train and holdout csv ##\n",
        "\n",
        "train_df = pd.read_csv(r\"/content/training_df_info.csv\")\n",
        "test_df = pd.read_csv(r\"/content/testing_df_info.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPGWErPdibUe",
        "outputId": "ad7b8191-85f6-411c-aebf-365b70b442fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 0]\n"
          ]
        }
      ],
      "source": [
        "# drop na\n",
        "train_df.dropna(inplace = True)\n",
        "test_df.dropna(inplace = True)\n",
        "\n",
        "# get the labels\n",
        "\n",
        "labels = train_df['target'].unique().tolist()\n",
        "print(labels)\n",
        "\n",
        "# create id <> mappings\n",
        "label2id = {\"Yes\": 1, \"No\" : 0}\n",
        "id2label = {1: \"Yes\", 0: \"No\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SMwgH5BrrNoa"
      },
      "outputs": [],
      "source": [
        "## get the test texts and test labels for benchmarking scores after finetuning ##\n",
        "test_texts = list(test_df['input_text'].values)\n",
        "test_labels = list(test_df['target'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F8axGtEimxe",
        "outputId": "19c56c5a-7d1a-4161-eed5-1088f6954807"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## load the tokenizer from HF, BertFastTokenizer\n",
        "## Idea is to finetune on this train datasets and then test on validation set\n",
        "## final benchmarking will be done on holdout set / test set\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\", max_length=512)\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)\n",
        "model.to(device)   #adding to cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BOHRlNDir2O",
        "outputId": "cdc0337a-81fa-48f8-b2d5-022412b5a202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1    435\n",
            "0    408\n",
            "Name: target, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "## checking the size of the entire train data ##\n",
        "SIZE = train_df.shape[0]\n",
        "\n",
        "## to get train and val samples, a simple train-test-split is performed\n",
        "## have checked the distribution of entire train data, it's kinda balanced\n",
        "\n",
        "print(train_df['target'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "W3m350PpntPz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_text, val_text, train_labels, val_labels = train_test_split(list(train_df['input_text'].values), list(train_df['target'].values), test_size = 0.2, random_state = 33)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mG6c0xfov3k",
        "outputId": "f99b2d63-6eaf-475f-c6d5-23667244e4a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(674, 169, 674, 169)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_text), len(val_text), len(train_labels), len(val_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "D6ogZL_7o40v"
      },
      "outputs": [],
      "source": [
        "## create the embeddings, token ids and attention-mask which will be the inp to the bert model for finetuning, using tokenizer\n",
        "\n",
        "train_encodings = tokenizer(train_text, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_text, truncation=True, padding=True)\n",
        "\n",
        "\n",
        "## create embeddings for the final test set too for score calculations\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCJDzVJGpf2J",
        "outputId": "95f64da2-9330-434e-c0e4-07333223ac15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_encodings.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV-4s68oppjw",
        "outputId": "88b77b74-f2cc-4b16-9311-55231f3557af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[101, 7479, 1012, 9033, 26941, 1012, 4012, 1013, 9686, 24761]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_encodings['input_ids'][0][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zQT1G5Pp1fs",
        "outputId": "7c710b59-970b-4f87-82e3-171ddbe061d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 0, 1, 0, 1, 0, 0, 0, 1, 0]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2ASrA360it_z"
      },
      "outputs": [],
      "source": [
        "class DataLoader(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset class for handling tokenized text data and corresponding labels.\n",
        "    Inherits from torch.utils.data.Dataset.\n",
        "    \"\"\"\n",
        "    def __init__(self, encodings, labels):\n",
        "        \"\"\"\n",
        "        Initializes the DataLoader class with encodings and labels.\n",
        "\n",
        "        Args:\n",
        "            encodings (dict): A dictionary containing tokenized input text data\n",
        "                              (e.g., 'input_ids', 'token_type_ids', 'attention_mask').\n",
        "            labels (list): A list of integer labels for the input text data.\n",
        "        \"\"\"\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Returns a dictionary containing tokenized data and the corresponding label for a given index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): The index of the data item to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            item (dict): A dictionary containing the tokenized data and the corresponding label.\n",
        "        \"\"\"\n",
        "        # Retrieve tokenized data for the given index\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        # Add the label for the given index to the item dictionary\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of data items in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            (int): The number of data items in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "bfVVNFtFiysX"
      },
      "outputs": [],
      "source": [
        "## create the DataLoader for train and val using the Dataloader class inherited from Dataset Class of Transformers\n",
        "\n",
        "train_dataloader = DataLoader(train_encodings, train_labels)\n",
        "val_dataloader = DataLoader(val_encodings, val_labels)\n",
        "\n",
        "test_dataloader = DataLoader(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SmTQuVELi20m"
      },
      "outputs": [],
      "source": [
        "\n",
        "def compute_metrics(pred):\n",
        "    \"\"\"\n",
        "    Computes accuracy, F1, precision, and recall for a given set of predictions.\n",
        "\n",
        "    Args:\n",
        "        pred (obj): An object containing label_ids and predictions attributes.\n",
        "            - label_ids (array-like): A 1D array of true class labels.\n",
        "            - predictions (array-like): A 2D array where each row represents\n",
        "              an observation, and each column represents the probability of\n",
        "              that observation belonging to a certain class.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the following metrics:\n",
        "            - Accuracy (float): The proportion of correctly classified instances.\n",
        "            - F1 (float): The macro F1 score, which is the harmonic mean of precision\n",
        "              and recall. Macro averaging calculates the metric independently for\n",
        "              each class and then takes the average.\n",
        "            - Precision (float): The macro precision, which is the number of true\n",
        "              positives divided by the sum of true positives and false positives.\n",
        "            - Recall (float): The macro recall, which is the number of true positives\n",
        "              divided by the sum of true positives and false negatives.\n",
        "    \"\"\"\n",
        "    # Extract true labels from the input object\n",
        "    labels = pred.label_ids\n",
        "\n",
        "    # Obtain predicted class labels by finding the column index with the maximum probability\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    # Compute macro precision, recall, and F1 score using sklearn's precision_recall_fscore_support function\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
        "\n",
        "    # Calculate the accuracy score using sklearn's accuracy_score function\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    # Return the computed metrics as a dictionary\n",
        "    return {\n",
        "        'Accuracy': acc,\n",
        "        'F1': f1,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "blZ5UsP3i8Ts"
      },
      "outputs": [],
      "source": [
        "!mkdir bert_model_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6IR8SUHni4CJ"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    # The output directory where the model predictions and checkpoints will be written\n",
        "    output_dir='/content/bert_model_output',\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    #  The number of epochs, defaults to 3.0\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    # Number of steps used for a linear warmup\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    logging_strategy='steps',\n",
        "   # TensorBoard log directory\n",
        "    logging_dir='./binary-class-logs',\n",
        "    logging_steps=50,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_strategy=\"steps\",\n",
        "    fp16=True,\n",
        "    load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "z5tupii9jEy2"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    # the pre-trained model that will be fine-tuned\n",
        "    model=model,\n",
        "     # training arguments that we defined above\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataloader,\n",
        "    eval_dataset=val_dataloader,\n",
        "    compute_metrics= compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "wcfcelW-jcRp",
        "outputId": "2564bbc3-7843-47c6-93a6-dcae3f2950c0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='215' max='215' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [215/215 02:16, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.581900</td>\n",
              "      <td>0.422458</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.768420</td>\n",
              "      <td>0.798077</td>\n",
              "      <td>0.785816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.163900</td>\n",
              "      <td>0.211074</td>\n",
              "      <td>0.952663</td>\n",
              "      <td>0.952287</td>\n",
              "      <td>0.950914</td>\n",
              "      <td>0.954752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.103000</td>\n",
              "      <td>0.233206</td>\n",
              "      <td>0.928994</td>\n",
              "      <td>0.928268</td>\n",
              "      <td>0.927372</td>\n",
              "      <td>0.929433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.077500</td>\n",
              "      <td>0.187856</td>\n",
              "      <td>0.952663</td>\n",
              "      <td>0.952057</td>\n",
              "      <td>0.952057</td>\n",
              "      <td>0.952057</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=215, training_loss=0.2191014705702316, metrics={'train_runtime': 137.5134, 'train_samples_per_second': 24.507, 'train_steps_per_second': 1.563, 'total_flos': 886684256563200.0, 'train_loss': 0.2191014705702316, 'epoch': 5.0})"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## train the model ##\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "L7gpq99XjmqE",
        "outputId": "3e2a460d-aa94-43af-c0ed-4a006f4b6d7e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22/22 00:10]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2edad0cb-24eb-425b-a243-e6f71815b106\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eval_loss</th>\n",
              "      <th>eval_Accuracy</th>\n",
              "      <th>eval_F1</th>\n",
              "      <th>eval_Precision</th>\n",
              "      <th>eval_Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>0.033205</td>\n",
              "      <td>0.98368</td>\n",
              "      <td>0.983679</td>\n",
              "      <td>0.983874</td>\n",
              "      <td>0.983836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>0.191988</td>\n",
              "      <td>0.95858</td>\n",
              "      <td>0.958205</td>\n",
              "      <td>0.956960</td>\n",
              "      <td>0.960071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>1.673532</td>\n",
              "      <td>0.68750</td>\n",
              "      <td>0.664373</td>\n",
              "      <td>0.681363</td>\n",
              "      <td>0.741667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2edad0cb-24eb-425b-a243-e6f71815b106')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2edad0cb-24eb-425b-a243-e6f71815b106 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2edad0cb-24eb-425b-a243-e6f71815b106');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-08c45f9f-4f99-48f5-be09-a009f6d81376\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08c45f9f-4f99-48f5-be09-a009f6d81376')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-08c45f9f-4f99-48f5-be09-a009f6d81376 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       eval_loss  eval_Accuracy   eval_F1  eval_Precision  eval_Recall\n",
              "train   0.033205        0.98368  0.983679        0.983874     0.983836\n",
              "val     0.191988        0.95858  0.958205        0.956960     0.960071\n",
              "test    1.673532        0.68750  0.664373        0.681363     0.741667"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## cal scores for train, val and test data ##\n",
        "\n",
        "q=[trainer.evaluate(eval_dataset=df_org) for df_org in [train_dataloader, val_dataloader, test_dataloader]]\n",
        "\n",
        "pd.DataFrame(q, index=[\"train\",\"val\", \"test\"]).iloc[:,:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "6aPdHvlojus8"
      },
      "outputs": [],
      "source": [
        "def predict(text):\n",
        "    \"\"\"\n",
        "    Predicts the class label for a given input text\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text for which the class label needs to be predicted.\n",
        "\n",
        "    Returns:\n",
        "        probs (torch.Tensor): Class probabilities for the input text.\n",
        "        pred_label_idx (torch.Tensor): The index of the predicted class label.\n",
        "        pred_label (str): The predicted class label.\n",
        "    \"\"\"\n",
        "    # Tokenize the input text and move tensors to the GPU if available\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Get model output (logits)\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    probs = outputs[0].softmax(1)\n",
        "    \"\"\" Explanation outputs: The BERT model returns a tuple containing the output logits (and possibly other elements depending on the model configuration). In this case, the output logits are the first element in the tuple, which is why we access it using outputs[0].\n",
        "\n",
        "    outputs[0]: This is a tensor containing the raw output logits for each class. The shape of the tensor is (batch_size, num_classes) where batch_size is the number of input samples (in this case, 1, as we are predicting for a single input text) and num_classes is the number of target classes.\n",
        "\n",
        "    softmax(1): The softmax function is applied along dimension 1 (the class dimension) to convert the raw logits into class probabilities. Softmax normalizes the logits so that they sum to 1, making them interpretable as probabilities. \"\"\"\n",
        "\n",
        "    # Get the index of the class with the highest probability\n",
        "    # argmax() finds the index of the maximum value in the tensor along a specified dimension.\n",
        "    # By default, if no dimension is specified, it returns the index of the maximum value in the flattened tensor.\n",
        "    pred_label_idx = probs.argmax()\n",
        "\n",
        "    # Now map the predicted class index to the actual class label\n",
        "    # Since pred_label_idx is a tensor containing a single value (the predicted class index),\n",
        "    # the .item() method is used to extract the value as a scalar\n",
        "    pred_label = model.config.id2label[pred_label_idx.item()]\n",
        "\n",
        "    return probs, pred_label_idx, pred_label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mXDy-g-uWlc",
        "outputId": "6cff8798-2c79-4c03-8fee-b4e89e622fbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNX0fQfbsP5N",
        "outputId": "f1da7a54-d270-49a1-d09f-3b0c3665d0e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 1/80 [00:00<00:08,  9.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 6/80 [00:00<00:03, 18.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 12/80 [00:00<00:03, 22.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▎       | 18/80 [00:00<00:02, 21.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▋       | 21/80 [00:01<00:02, 20.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 24/80 [00:01<00:03, 17.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▋      | 29/80 [00:01<00:02, 18.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 32/80 [00:01<00:02, 20.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 38/80 [00:02<00:02, 18.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 43/80 [00:02<00:01, 19.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▊    | 46/80 [00:02<00:02, 16.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 51/80 [00:02<00:01, 18.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 54/80 [00:02<00:01, 20.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 60/80 [00:03<00:00, 20.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 63/80 [00:03<00:00, 21.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▋ | 69/80 [00:03<00:00, 20.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 75/80 [00:03<00:00, 21.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:04<00:00, 19.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "Predicting info....\n",
            "0.5762711864406781\n",
            "[[38 22]\n",
            " [ 3 17]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "## cal scores for the same\n",
        "\n",
        "actual_labels = test_labels\n",
        "pred_labels = []\n",
        "for text in tqdm(test_texts):\n",
        "  # print(text)\n",
        "  print(\"Predicting info....\")\n",
        "  output_response = predict(text)\n",
        "\n",
        "  if output_response:\n",
        "    pred_labels.append(list(output_response)[1].item())\n",
        "\n",
        "assert len(actual_labels) == len(pred_labels), \"Mismatch in labels size\"\n",
        "\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "print(f1_score(actual_labels, pred_labels))\n",
        "print(confusion_matrix(actual_labels, pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVMuVaVGktDo",
        "outputId": "dfaa13e7-6795-41a8-bf70-80ddd3df3fc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('bert-base-uncased-finetune-raw-data/tokenizer_config.json',\n",
              " 'bert-base-uncased-finetune-raw-data/special_tokens_map.json',\n",
              " 'bert-base-uncased-finetune-raw-data/vocab.txt',\n",
              " 'bert-base-uncased-finetune-raw-data/added_tokens.json',\n",
              " 'bert-base-uncased-finetune-raw-data/tokenizer.json')"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## save the fine-tuned model ##\n",
        "\n",
        "model_path = \"bert-base-uncased-finetune-raw-data\"\n",
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "KvgYZVYik5Qw"
      },
      "outputs": [],
      "source": [
        "## load the model from the local and do prediction ##\n",
        "\n",
        "model_path = \"bert-base-uncased-finetune-raw-data\"\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_path).to(device)\n",
        "tokenizer= BertTokenizerFast.from_pretrained(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz-NQ1O5laMg",
        "outputId": "122815ad-95a2-4e0d-f88c-9eda6ffcd786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[0.0145, 0.9855]], device='cuda:0', grad_fn=<SoftmaxBackward0>), tensor(1, device='cuda:0'), 'Yes')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(predict(test_texts[66]))\n",
        "\n",
        "test_labels[66]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "cuDg-iNClb1P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
